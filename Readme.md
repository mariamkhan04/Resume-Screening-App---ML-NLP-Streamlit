# ğŸ“„ Automated Resume Screening App

## ğŸ¯ Project Objective

Build an **AI-powered Resume Screening App** using **NLP + Machine Learning + Streamlit** to help recruiters automatically classify resumes, extract skills, and compute candidate fit scores.

[Preview App](https://automated-resume-screening-ml.streamlit.app/#automated-resume-screening)

---

## ğŸ“‚ Dataset

* Source: [Kaggle - Resume Dataset](https://www.kaggle.com/datasets) (Resume Dataset, \~1000 resumes, 25 job categories)
* Columns: `Category` (target job role), `Resume` (raw text)

---

## âš™ï¸ Applied Concepts & Steps

1. **Text Preprocessing**: lowercasing, regex cleaning, stopword removal, lemmatization
2. **Feature Engineering**: TF-IDF vectorization (unigrams + bigrams)
3. **Model Training**: Logistic Regression, Naive Bayes (final model = Logistic Regression, \~99% accuracy)
4. **Fit Score Formula**: `70% prediction probability + 30% skill matching`
5. **Deployment**: Streamlit app with file upload & prediction

---

## ğŸ” Key Insights

* Class imbalance observed (Java Dev = 84 vs Advocate = 20 resumes)
* Resumes contained noisy data (emails, URLs, headers â†’ cleaned via preprocessing)
* Logistic Regression handled imbalanced classes better than Naive Bayes
* Accurate classification even for small classes like Advocate

---

## ğŸ’¡ Skills Learnt

NLP Â· Text Preprocessing Â· TF-IDF Â· Logistic Regression Â· Naive Bayes Â· EDA Â· Regex Â· NLTK Â· scikit-learn Â· Streamlit

---

## ğŸ› ï¸ Project Structure & Run

```
## ğŸ› ï¸ Project Structure

resume_screening/
â”œâ”€â”€ nltk_data/                    # NLTK stopwords, tokenizers
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ resumes_dataset.csv       # Original dataset
â”‚   â”œâ”€â”€ resumes_df.pkl            # Pickled preprocessed dataset
â”‚   â”œâ”€â”€ file_utils.py             # Extract text from PDF/DOCX
â”‚   â”œâ”€â”€ skills_db.py              # Skills database per job category
â”‚   â”œâ”€â”€ app_helpers.py            # Helper functions for skills, education, fit score
â”‚
â”œâ”€â”€ eda.ipynb                     # Exploratory Data Analysis
â”œâ”€â”€ preprocess_utils.ipynb        # Preprocessing pipeline
â”œâ”€â”€ train_model.py                # ML model training script
â”œâ”€â”€ app.py                        # Streamlit app
â”œâ”€â”€ Readme.md                     # Project documentation
â””â”€â”€ requirements.txt              # Python dependencies
```

Run locally:

```bash
pip install -r src/requirements.txt
streamlit run app.py
```

---

## ğŸ”® Future Scope

* Deploy on Streamlit Cloud / Hugging Face
* Use advanced NLP models (BERT, DistilBERT)
* Handle class imbalance with SMOTE/weighted loss
* Enhance fit score with real HR metrics

---

## âœ¨ Author

Developed by **[Mariam Khan](https://www.linkedin.com/in/mariam-khan0424)** ğŸ¯
